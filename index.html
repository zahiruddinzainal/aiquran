<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>CodePen - MediaPipe HandGestureRecognizer Task for web</title>
  <link rel="stylesheet" href="./style.css">
  <link href="./scripts/material.min.css" rel="stylesheet">
  <script src="./scripts/material.min.js"></script>
</head>

<body>
  <section id="demos" class="invisible">
    Quran AI

    <div>
      <div class="image-container">
        <img id="right-image" src="quran/quran_0002.jpg" alt="Image 2">
        <img id="left-image" src="quran/quran_0001.jpg" alt="Image 1">
      </div>
      <div class="controls">
        <button id="prev-button">Previous</button>
        <button id="next-button">Next</button>
      </div>
    </div>
    <div id="liveView" class="videoView">
      <button id="webcamButton" class="mdc-button mdc-button--raised">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">ENABLE WEBCAM</span>
      </button>
      <div style="position: relative;">
        <video id="webcam" autoplay playsinline></video>
        <canvas class="output_canvas" id="output_canvas" width="1280" height="720"
          style="position: absolute; left: 0px; top: 0px;"></canvas>
        <p id='gesture_output' class="output">
      </div>
    </div>
  </section>
  <!-- partial -->
  <script type="module">
    const leftImage = document.getElementById("left-image");
    const rightImage = document.getElementById("right-image");
    const prevButton = document.getElementById("prev-button");
    const nextButton = document.getElementById("next-button");

    let currentImageIndex = 1;
    const totalImages = 624; // Total number of images

    function getFormattedImageIndex(index) {
      // Convert the image index to a four-digit string, e.g., 1 -> "0001"
      return String(index).padStart(4, '0');
    }

    function showImages(leftIndex, rightIndex) {
      leftImage.src = `quran/quran_${getFormattedImageIndex(leftIndex)}.jpg`;
      rightImage.src = `quran/quran_${getFormattedImageIndex(rightIndex)}.jpg`;
    }

    function goToPreviousImage() {
      if (currentImageIndex > 1) {
        currentImageIndex--;
        showImages(currentImageIndex, currentImageIndex + 1);
      }
    }

    function goToNextImage() {
      if (currentImageIndex < totalImages) {
        currentImageIndex++;
        showImages(currentImageIndex, currentImageIndex + 1);
      }
    }

    prevButton.addEventListener("click", goToPreviousImage);
    nextButton.addEventListener("click", goToNextImage);

    // Initialize with the first and second images
    showImages(currentImageIndex, currentImageIndex + 1);
    // Copyright 2023 The MediaPipe Authors.
    // Licensed under the Apache License, Version 2.0 (the "License");
    // you may not use this file except in compliance with the License.
    // You may obtain a copy of the License at
    //      http://www.apache.org/licenses/LICENSE-2.0
    // Unless required by applicable law or agreed to in writing, software
    // distributed under the License is distributed on an "AS IS" BASIS,
    // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    // See the License for the specific language governing permissions and
    // limitations under the License.
    
    import { GestureRecognizer, FilesetResolver, DrawingUtils } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
    const demosSection = document.getElementById("demos");
    let gestureRecognizer;
    let runningMode = "IMAGE";
    let enableWebcamButton;
    let webcamRunning = false;
    const videoHeight = "360px";
    const videoWidth = "480px";
    // Before we can use HandLandmarker class we must wait for it to finish
    // loading. Machine Learning models can be large and take a moment to
    // get everything needed to run.
    const createGestureRecognizer = async () => {
      const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
      gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
          delegate: "GPU"
        },
        runningMode: runningMode
      });
      demosSection.classList.remove("invisible");
    };
    createGestureRecognizer();
    /********************************************************************
    // Demo 1: Detect hand gestures in images
    ********************************************************************/
    const imageContainers = document.getElementsByClassName("detectOnClick");
    for (let i = 0; i < imageContainers.length; i++) {
      imageContainers[i].children[0].addEventListener("click", handleClick);
    }
    async function handleClick(event) {
      if (!gestureRecognizer) {
        alert("Please wait for gestureRecognizer to load");
        return;
      }
      if (runningMode === "VIDEO") {
        runningMode = "IMAGE";
        await gestureRecognizer.setOptions({ runningMode: "IMAGE" });
      }
      // Remove all previous landmarks
      const allCanvas = event.target.parentNode.getElementsByClassName("canvas");
      for (var i = allCanvas.length - 1; i >= 0; i--) {
        const n = allCanvas[i];
        n.parentNode.removeChild(n);
      }
      const results = gestureRecognizer.recognize(event.target);
      // View results in the console to see their format
      console.log(results);
      if (results.gestures.length > 0) {
        const p = event.target.parentNode.childNodes[3];
        p.setAttribute("class", "info");
        const categoryName = results.gestures[0][0].categoryName;
        const categoryScore = parseFloat(results.gestures[0][0].score * 100).toFixed(2);
        const handedness = results.handednesses[0][0].displayName;
        p.innerText = `GestureRecognizer: ${categoryName}\n Confidence: ${categoryScore}%\n Handedness: ${handedness}`;
        p.style =
          "left: 0px;" +
          "top: " +
          event.target.height +
          "px; " +
          "width: " +
          (event.target.width - 10) +
          "px;";
        const canvas = document.createElement("canvas");
        canvas.setAttribute("class", "canvas");
        canvas.setAttribute("width", event.target.naturalWidth + "px");
        canvas.setAttribute("height", event.target.naturalHeight + "px");
        canvas.style =
          "left: 0px;" +
          "top: 0px;" +
          "width: " +
          event.target.width +
          "px;" +
          "height: " +
          event.target.height +
          "px;";
        event.target.parentNode.appendChild(canvas);
        const canvasCtx = canvas.getContext("2d");
        const drawingUtils = new DrawingUtils(canvasCtx);
        for (const landmarks of results.landmarks) {
          drawingUtils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, {
            color: "#00FF00",
            lineWidth: 5
          });
          drawingUtils.drawLandmarks(landmarks, {
            color: "#FF0000",
            lineWidth: 1
          });
        }
      }
    }
    /********************************************************************
    // Demo 2: Continuously grab image from webcam stream and detect it.
    ********************************************************************/
    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");
    const gestureOutput = document.getElementById("gesture_output");
    // Check if webcam access is supported.
    function hasGetUserMedia() {
      return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
    }
    // If webcam supported, add event listener to button for when user
    // wants to activate it.
    if (hasGetUserMedia()) {
      enableWebcamButton = document.getElementById("webcamButton");
      enableWebcamButton.addEventListener("click", enableCam);
    }
    else {
      console.warn("getUserMedia() is not supported by your browser");
    }
    // Enable the live webcam view and start detection.
    function enableCam(event) {
      if (!gestureRecognizer) {
        alert("Please wait for gestureRecognizer to load");
        return;
      }
      if (webcamRunning === true) {
        webcamRunning = false;
        enableWebcamButton.innerText = "ENABLE PREDICTIONS";
      }
      else {
        webcamRunning = true;
        enableWebcamButton.innerText = "DISABLE PREDICTIONS";
      }
      // getUsermedia parameters.
      const constraints = {
        video: true
      };
      // Activate the webcam stream.
      navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
      });
    }
    let lastVideoTime = -1;
    let results = undefined;
    let firstDetection = true;

    async function predictWebcam() {
      const webcamElement = document.getElementById("webcam");
      // Now let's start detecting the stream.
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await gestureRecognizer.setOptions({ runningMode: "VIDEO" });
      }
      let nowInMs = Date.now();
      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        results = gestureRecognizer.recognizeForVideo(video, nowInMs);
      }
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      const drawingUtils = new DrawingUtils(canvasCtx);
      canvasElement.style.height = videoHeight;
      webcamElement.style.height = videoHeight;
      canvasElement.style.width = videoWidth;
      webcamElement.style.width = videoWidth;
      if (results.landmarks) {
        for (const landmarks of results.landmarks) {
          drawingUtils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, {
            color: "#00FF00",
            lineWidth: 5
          });
          drawingUtils.drawLandmarks(landmarks, {
            color: "#FF0000",
            lineWidth: 2
          });
        }
      }

      canvasCtx.restore();
      if (results.gestures.length > 0) {
        gestureOutput.style.display = "block";
        gestureOutput.style.width = videoWidth;
        const categoryName = results.gestures[0][0].categoryName;
        const categoryScore = parseFloat(results.gestures[0][0].score * 100).toFixed(2);
        const handedness = results.handednesses[0][0].displayName;
        gestureOutput.innerText = `GestureRecognizer: ${categoryName}\n Confidence: ${categoryScore} %\n Handedness: ${handedness}`;

        if (categoryName == "Pointing_Up" && firstDetection) {
          console.log("UP");
          nextButton.click();
          firstDetection = false; // Set the flag to false to prevent further clicks
        }
        if (categoryName == "Open_Palm" && firstDetection) {
          console.log("PALM");
          prevButton.click();
          firstDetection = false; // Set the flag to false to prevent further clicks
        }
      } else {
        gestureOutput.style.display = "none";
        firstDetection = true; // Reset the flag when no gestures are detected
      }
      // Call this function again to keep predicting when the browser is ready.
      if (webcamRunning === true) {
        window.requestAnimationFrame(predictWebcam);
      }
    }
  </script>

</body>

</html>